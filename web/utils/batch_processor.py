#!/usr/bin/env python3
"""
æ‰¹é‡åˆ†æå¤„ç†å™¨
æ”¯æŒå¤šä¸ªè‚¡ç¥¨ä»£ç çš„å¹¶å‘åˆ†æ
"""

import streamlit as st
import threading
import time
import queue
import os
from typing import List, Dict, Any, Optional
from datetime import datetime
import traceback
import uuid

# å¯¼å…¥æ—¥å¿—æ¨¡å—
from tradingagents.utils.logging_manager import get_logger
logger = get_logger('batch_processor')

# å¯¼å…¥åˆ†æè¿è¡Œå™¨
from utils.analysis_runner import run_stock_analysis, validate_analysis_params


class BatchAnalysisProcessor:
    """æ‰¹é‡åˆ†æå¤„ç†å™¨"""
    
    def __init__(self):
        self.analysis_queue = queue.Queue()
        self.results_queue = queue.Queue()
        self.active_threads = {}
        self.is_running = False
        self.last_activity_time = None  # è®°å½•æœ€åæ´»åŠ¨æ—¶é—´
        self.completed_tasks_log = []  # è®°å½•å®Œæˆä»»åŠ¡çš„æ—¥å¿—
        self._lock = threading.Lock()  # çº¿ç¨‹å®‰å…¨é”
        
    def parse_stock_symbols(self, input_text: str) -> List[str]:
        """è§£æè‚¡ç¥¨ä»£ç è¾“å…¥æ–‡æœ¬"""
        if not input_text:
            return []
        
        # æ”¯æŒå¤šç§åˆ†éš”ç¬¦ï¼šæ¢è¡Œã€é€—å·ã€åˆ†å·ã€ç©ºæ ¼
        import re
        symbols = re.split(r'[,;\s\n]+', input_text.strip())
        
        # æ¸…ç†å’ŒéªŒè¯è‚¡ç¥¨ä»£ç 
        cleaned_symbols = []
        for symbol in symbols:
            symbol = symbol.strip().upper()
            if symbol:
                cleaned_symbols.append(symbol)
        
        return list(set(cleaned_symbols))  # å»é‡
    
    def add_analysis_task(self, symbol: str, params: Dict[str, Any], llm_config: Optional[Dict[str, str]] = None) -> str:
        """æ·»åŠ åˆ†æä»»åŠ¡"""
        task_id = str(uuid.uuid4())[:8]
        task = {
            'task_id': task_id,
            'symbol': symbol,
            'params': params,
            'llm_config': llm_config,
            'status': 'pending',
            'created_at': datetime.now(),
            'start_time': None,
            'end_time': None,
            'result': None,
            'error': None
        }
        
        self.analysis_queue.put(task)
        logger.info(f"æ·»åŠ åˆ†æä»»åŠ¡: {symbol} (ID: {task_id})")
        return task_id
    
    def run_analysis_worker(self, task: Dict[str, Any]):
        """è¿è¡Œå•ä¸ªåˆ†æä»»åŠ¡çš„å·¥ä½œçº¿ç¨‹"""
        task_id = task['task_id']
        symbol = task['symbol']
        
        try:
            logger.info(f"å¼€å§‹åˆ†æä»»åŠ¡: {symbol} (ID: {task_id})")
            task['status'] = 'running'
            task['start_time'] = datetime.now()
            
            # ä½¿ç”¨ä¼ å…¥çš„LLMé…ç½®ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤é…ç½®
            llm_config = task.get('llm_config') or {}
            
            # ä»é…ç½®ä¸­è·å–LLMè®¾ç½®ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–é»˜è®¤å€¼
            llm_provider = llm_config.get('llm_provider') or os.getenv('DEFAULT_LLM_PROVIDER', 'deepseek')
            llm_model = llm_config.get('llm_model') or os.getenv('DEFAULT_LLM_MODEL', 'deepseek-chat')
            
            logger.info(f"ä½¿ç”¨LLMé…ç½®: provider={llm_provider}, model={llm_model}")
            
            # è¿è¡Œåˆ†æ - åªä¼ é€’run_stock_analysiséœ€è¦çš„å‚æ•°
            result = run_stock_analysis(
                stock_symbol=symbol,
                analysis_date=task['params'].get('analysis_date'),
                analysts=task['params'].get('analysts', []),
                research_depth=task['params'].get('research_depth', 3),
                llm_provider=llm_provider,
                llm_model=llm_model,
                market_type=task['params'].get('market_type', 'ç¾è‚¡'),
                progress_callback=None  # æ‰¹é‡åˆ†æä¸ä½¿ç”¨è¿›åº¦å›è°ƒ
            )
            
            task['status'] = 'completed'
            task['end_time'] = datetime.now()
            task['result'] = result
            
            # æ›´æ–°æœ€åæ´»åŠ¨æ—¶é—´
            self.last_activity_time = datetime.now()
            
            # è®°å½•å®Œæˆä»»åŠ¡æ—¥å¿—
            completion_log = {
                'task_id': task_id,
                'symbol': symbol,
                'completed_at': self.last_activity_time,
                'duration': (task['end_time'] - task['start_time']).total_seconds()
            }
            self.completed_tasks_log.append(completion_log)
            
            logger.info(f"å®Œæˆåˆ†æä»»åŠ¡: {symbol} (ID: {task_id})")
            
        except Exception as e:
            task['status'] = 'failed'
            task['end_time'] = datetime.now()
            task['error'] = str(e)
            
            # å³ä½¿å¤±è´¥ä¹Ÿæ›´æ–°æ´»åŠ¨æ—¶é—´
            self.last_activity_time = datetime.now()
            
            logger.error(f"åˆ†æä»»åŠ¡å¤±è´¥: {symbol} (ID: {task_id}) - {e}")
            logger.error(traceback.format_exc())
        
        finally:
            # å°†ç»“æœæ”¾å…¥ç»“æœé˜Ÿåˆ—
            self.results_queue.put(task)
            
            # ä»æ´»åŠ¨çº¿ç¨‹ä¸­ç§»é™¤ - ä½¿ç”¨çº¿ç¨‹å®‰å…¨çš„æ–¹å¼
            with self._lock:
                if task_id in self.active_threads:
                    del self.active_threads[task_id]
                    logger.info(f"âœ… çº¿ç¨‹å®Œæˆå¹¶æ¸…ç†: {task_id}")
            
            logger.info(f"ğŸ“¦ ä»»åŠ¡ç»“æœå·²æ”¾å…¥é˜Ÿåˆ—: {task_id}")
    
    def start_batch_analysis(self, symbols: List[str], analysis_params: Dict[str, Any], llm_config: Optional[Dict[str, str]] = None) -> List[str]:
        """å¼€å§‹æ‰¹é‡åˆ†æ"""
        if not symbols:
            return []
        
        task_ids = []
        self.is_running = True
        
        logger.info(f"å¼€å§‹æ‰¹é‡åˆ†æ {len(symbols)} ä¸ªè‚¡ç¥¨ä»£ç ")
        
        for symbol in symbols:
            # éªŒè¯å‚æ•° - åªä¼ é€’validate_analysis_paramséœ€è¦çš„å‚æ•°
            try:
                validate_analysis_params(
                    stock_symbol=symbol,
                    analysis_date=analysis_params.get('analysis_date'),
                    analysts=analysis_params.get('analysts', []),
                    research_depth=analysis_params.get('research_depth', 3),
                    market_type=analysis_params.get('market_type', 'ç¾è‚¡')
                )
                
                # ä¸ºrun_stock_analysiså‡†å¤‡å®Œæ•´çš„å‚æ•°é›†
                params = {
                    'analysis_date': analysis_params.get('analysis_date'),
                    'analysts': analysis_params.get('analysts', []),
                    'research_depth': analysis_params.get('research_depth', 3),
                    'market_type': analysis_params.get('market_type', 'ç¾è‚¡'),
                    'include_sentiment': analysis_params.get('include_sentiment', True),
                    'include_risk_assessment': analysis_params.get('include_risk_assessment', True),
                    'custom_prompt': analysis_params.get('custom_prompt', '')
                }
                
                # æ·»åŠ ä»»åŠ¡
                task_id = self.add_analysis_task(symbol, params, llm_config)
                task_ids.append(task_id)
                
                # å¯åŠ¨å·¥ä½œçº¿ç¨‹
                task = self.analysis_queue.get()
                thread = threading.Thread(
                    target=self.run_analysis_worker,
                    args=(task,),
                    daemon=True
                )
                thread.start()
                
                # çº¿ç¨‹å®‰å…¨åœ°æ·»åŠ åˆ°æ´»åŠ¨çº¿ç¨‹å­—å…¸
                with self._lock:
                    self.active_threads[task_id] = thread
                
                logger.info(f"ğŸš€ å¯åŠ¨åˆ†æçº¿ç¨‹: {symbol} (ID: {task_id})")
                
            except Exception as e:
                logger.error(f"åˆ›å»ºä»»åŠ¡å¤±è´¥: {symbol} - {e}")
        
        return task_ids
    
    def get_progress_status(self) -> Dict[str, Any]:
        """è·å–æ‰¹é‡åˆ†æè¿›åº¦çŠ¶æ€ - æ”¹è¿›ç‰ˆæœ¬æ”¯æŒæ›´å‡†ç¡®çš„çŠ¶æ€æ£€æµ‹"""
        completed_results = []
        
        # æ”¶é›†æ‰€æœ‰å®Œæˆçš„ç»“æœ
        result_count = 0
        while not self.results_queue.empty():
            try:
                result = self.results_queue.get_nowait()
                completed_results.append(result)
                result_count += 1
            except queue.Empty:
                break
        
        if result_count > 0:
            logger.info(f"ğŸ“¥ ä»é˜Ÿåˆ—ä¸­è·å–äº† {result_count} ä¸ªå®Œæˆçš„ç»“æœ")
        
        # æ¸…ç†å·²å®Œæˆçš„çº¿ç¨‹ - çº¿ç¨‹å®‰å…¨ + æ­»çº¿ç¨‹æ£€æµ‹
        with self._lock:
            finished_threads = []
            dead_threads = []
            for task_id, thread in list(self.active_threads.items()):
                if not thread.is_alive():
                    finished_threads.append(task_id)
                    dead_threads.append(task_id)
                    logger.info(f"ğŸ’€ æ£€æµ‹åˆ°æ­»çº¿ç¨‹: {task_id[:8]} (çº¿ç¨‹å·²ç»“æŸä½†æœªæ¸…ç†)")
            
            # ç§»é™¤å·²å®Œæˆçš„çº¿ç¨‹
            for task_id in finished_threads:
                if task_id in self.active_threads:
                    del self.active_threads[task_id]
                    logger.info(f"ğŸ§¹ æ¸…ç†å·²å®Œæˆçš„çº¿ç¨‹: {task_id[:8]}")
                    
                    # å¦‚æœçº¿ç¨‹æ­»äº¡ä½†æ²¡æœ‰ç»“æœï¼Œåˆ›å»ºä¸€ä¸ªå‡ç»“æœæ¥è¡¨ç¤ºå®Œæˆ
                    if task_id not in [r.get('task_id') for r in completed_results]:
                        fake_result = {
                            'task_id': task_id,
                            'symbol': getattr(thread, 'symbol', 'Unknown'),
                            'success': True,  # å‡è®¾æˆåŠŸï¼Œå› ä¸ºæ²¡æœ‰å¼‚å¸¸
                            'auto_detected': True,
                            'completion_time': datetime.now().strftime("%H:%M:%S")
                        }
                        completed_results.append(fake_result)
                        logger.info(f"ğŸ¤– ä¸ºæ­»çº¿ç¨‹åˆ›å»ºå‡ç»“æœ: {task_id[:8]}")
            
            # ç»Ÿè®¡çŠ¶æ€
            running_tasks = len(self.active_threads)
            
        completed_tasks = len(completed_results)
        total_tasks = running_tasks + completed_tasks
        
        logger.debug(f"ğŸ“Š çŠ¶æ€ç»Ÿè®¡: è¿è¡Œä¸­={running_tasks}, å·²å®Œæˆ={completed_tasks}, æ€»è®¡={total_tasks}, æ­»çº¿ç¨‹={len(dead_threads)}")
        
        # æ£€æŸ¥æ˜¯å¦çœŸçš„åœ¨è¿è¡Œä¸­ - åŸºäºå¤šé‡æ¡ä»¶åˆ¤æ–­
        is_actually_running = self.is_running and running_tasks > 0
        
        # æ™ºèƒ½å®Œæˆæ£€æµ‹ï¼šå¦‚æœæ²¡æœ‰è¿è¡Œä¸­çš„ä»»åŠ¡ï¼Œä¸”æœ€åæ´»åŠ¨æ—¶é—´è¶…è¿‡5ç§’ï¼Œè®¤ä¸ºå·²å®Œæˆ
        if self.is_running and running_tasks == 0:
            time_since_activity = (datetime.now() - self.last_activity_time).total_seconds() if self.last_activity_time else 0
            
            if completed_tasks > 0 and time_since_activity > 5:  # é™ä½åˆ°5ç§’
                self.is_running = False
                is_actually_running = False
                logger.info(f"[è¿›åº¦] âœ… æ™ºèƒ½æ£€æµ‹ï¼šæ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼æ€»è®¡: {completed_tasks}ä¸ªï¼Œæœ€åæ´»åŠ¨æ—¶é—´: {time_since_activity:.1f}ç§’å‰")
            elif completed_tasks > 0:
                # çŸ­æš‚ç­‰å¾…æœŸé—´ï¼Œä»æ ‡è®°ä¸ºè¿è¡Œä¸­ä½†æç¤ºå³å°†å®Œæˆ
                logger.info(f"[è¿›åº¦] ğŸ”„ ç­‰å¾…ç¡®è®¤å®ŒæˆçŠ¶æ€... å·²å®Œæˆ: {completed_tasks}ä¸ªï¼Œè·ç¦»æœ€åæ´»åŠ¨: {time_since_activity:.1f}ç§’")
        
        # å¦‚æœæ£€æµ‹åˆ°æ­»çº¿ç¨‹ï¼Œç«‹å³æ ‡è®°ä¸ºå®Œæˆ
        if len(dead_threads) > 0 and running_tasks == 0:
            self.is_running = False
            is_actually_running = False
            logger.info(f"[è¿›åº¦] âœ… åŸºäºæ­»çº¿ç¨‹æ£€æµ‹ï¼šæ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼æ£€æµ‹åˆ°{len(dead_threads)}ä¸ªæ­»çº¿ç¨‹")
        
        # å¦‚æœæ²¡æœ‰è¿è¡Œä¸­çš„ä»»åŠ¡ï¼Œæ ‡è®°ä¸ºåœæ­¢
        if self.is_running and running_tasks == 0 and completed_tasks > 0:
            time_since_activity = (datetime.now() - self.last_activity_time).total_seconds() if self.last_activity_time else 999
            if time_since_activity > 3:  # é™ä½åˆ°3ç§’
                self.is_running = False
                is_actually_running = False
                logger.info(f"[è¿›åº¦] âœ… æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼æ€»è®¡: {completed_tasks}ä¸ª")
        
        status = {
            'total_tasks': total_tasks,
            'running_tasks': running_tasks,
            'completed_tasks': completed_tasks,
            'is_running': is_actually_running,
            'completed_results': completed_results,
            'progress_percentage': (completed_tasks / total_tasks * 100) if total_tasks > 0 else 0,
            'last_update_time': datetime.now().strftime("%H:%M:%S"),
            'last_activity_time': self.last_activity_time.strftime("%H:%M:%S") if self.last_activity_time else None,
            'time_since_last_activity': (datetime.now() - self.last_activity_time).total_seconds() if self.last_activity_time else None,
            'completed_tasks_count': len(self.completed_tasks_log),
            'dead_threads_detected': len(dead_threads),
            'force_completion': len(dead_threads) > 0 and running_tasks == 0  # å¼ºåˆ¶å®Œæˆæ ‡è¯†
        }
        
        # å¦‚æœæ²¡æœ‰è¿è¡Œä¸­çš„ä»»åŠ¡ï¼Œæ ‡è®°ä¸ºå®Œæˆ
        if running_tasks == 0:
            self.is_running = False
        
        return status
    
    def stop_all_tasks(self):
        """åœæ­¢æ‰€æœ‰ä»»åŠ¡"""
        logger.info("åœæ­¢æ‰€æœ‰æ‰¹é‡åˆ†æä»»åŠ¡")
        self.is_running = False
        
        # æ¸…ç©ºé˜Ÿåˆ—
        while not self.analysis_queue.empty():
            try:
                self.analysis_queue.get_nowait()
            except queue.Empty:
                break
        
        # ç­‰å¾…æ´»åŠ¨çº¿ç¨‹å®Œæˆï¼ˆè®¾ç½®è¶…æ—¶ï¼‰
        for task_id, thread in list(self.active_threads.items()):
            if thread.is_alive():
                thread.join(timeout=1.0)  # ç­‰å¾…1ç§’
        
        self.active_threads.clear()


# å…¨å±€æ‰¹é‡å¤„ç†å™¨å®ä¾‹
if 'batch_processor' not in st.session_state:
    st.session_state.batch_processor = BatchAnalysisProcessor()


def get_batch_processor() -> BatchAnalysisProcessor:
    """è·å–æ‰¹é‡å¤„ç†å™¨å®ä¾‹"""
    return st.session_state.batch_processor
